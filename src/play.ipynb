{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 08:50:05.871064: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from poem_env import PoemGenerationEnv\n",
    "from poem_dql import DQLAgent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/temp_romanian_words.csv')\n",
    "df = df[df['joint_syllables'] != 'not-found']\n",
    "df.to_csv('../data/temporary_romanian_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12719 12719\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "df = pd.read_csv('../data/temporary_romanian_words.csv')\n",
    "syls = list(df['syllables'])\n",
    "new_syls = []\n",
    "for s in syls:\n",
    "    s = eval(s)\n",
    "    i=0\n",
    "    while i < (len(s)):\n",
    "        if '(' in s[i]:\n",
    "            break\n",
    "        i+=1\n",
    "    new_syls.append(s[:i])\n",
    "            \n",
    "print (len(new_syls), len(df))\n",
    "df['syllables'] = new_syls\n",
    "df.to_csv('../data/temporary2_romanian_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/temporary2_romanian_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: {'poem': ['bibliomanie'], 'verse': [], 'syllables_left': 6, 'verse_index': 1}\n",
      "Reward: 0\n",
      "Done: False\n",
      "State: {'poem': ['bibliomanie'], 'verse': ['camarilă'], 'syllables_left': 2, 'verse_index': 1}\n",
      "Reward: 1\n",
      "Done: False\n",
      "State: {'poem': ['bibliomanie', 'camarilă clujean'], 'verse': [], 'syllables_left': 6, 'verse_index': 2}\n",
      "Reward: 50\n",
      "Done: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize the environment\n",
    "env = PoemGenerationEnv(df, num_verses=2, syllables_per_verse=6, rhyme_data=3)\n",
    "\n",
    "# Interact with the environment\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.sample_action()  # Random action (replace with DQL model's action)\n",
    "    state, reward, done = env.step(action)\n",
    "    print(f\"State: {state}\")\n",
    "    print(f\"Reward: {reward}\")\n",
    "    print(f\"Done: {done}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "episodes = 500\n",
    "batch_size = 32\n",
    "state_size = 3  # For example: poem length, syllables left, verse index\n",
    "action_size = len(env.vocab)  # Vocabulary size\n",
    "target_update_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 2/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 3/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 4/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 5/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 6/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 7/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 8/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 9/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 10/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 11/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 12/500, Total Reward: -15, Epsilon: 1.00\n",
      "Episode 13/500, Total Reward: -15, Epsilon: 0.98\n",
      "Episode 14/500, Total Reward: -15, Epsilon: 0.97\n",
      "Episode 15/500, Total Reward: -15, Epsilon: 0.96\n",
      "Episode 16/500, Total Reward: -15, Epsilon: 0.95\n",
      "Episode 17/500, Total Reward: -15, Epsilon: 0.94\n",
      "Episode 18/500, Total Reward: -15, Epsilon: 0.92\n",
      "Episode 19/500, Total Reward: -15, Epsilon: 0.89\n",
      "Episode 20/500, Total Reward: -15, Epsilon: 0.87\n",
      "Episode 21/500, Total Reward: -15, Epsilon: 0.86\n",
      "Episode 22/500, Total Reward: -15, Epsilon: 0.85\n",
      "Episode 23/500, Total Reward: -15, Epsilon: 0.85\n",
      "Episode 24/500, Total Reward: -15, Epsilon: 0.84\n",
      "Episode 25/500, Total Reward: -15, Epsilon: 0.82\n",
      "Episode 26/500, Total Reward: -15, Epsilon: 0.81\n",
      "Episode 27/500, Total Reward: -15, Epsilon: 0.78\n",
      "Episode 28/500, Total Reward: -15, Epsilon: 0.77\n",
      "Episode 29/500, Total Reward: -15, Epsilon: 0.76\n",
      "Episode 30/500, Total Reward: -15, Epsilon: 0.74\n",
      "Episode 31/500, Total Reward: -15, Epsilon: 0.73\n",
      "Episode 32/500, Total Reward: -15, Epsilon: 0.73\n",
      "Episode 33/500, Total Reward: -15, Epsilon: 0.72\n",
      "Episode 34/500, Total Reward: -15, Epsilon: 0.71\n",
      "Episode 35/500, Total Reward: 50, Epsilon: 0.68\n",
      "Episode 36/500, Total Reward: -15, Epsilon: 0.67\n",
      "Episode 37/500, Total Reward: -15, Epsilon: 0.66\n",
      "Episode 38/500, Total Reward: -15, Epsilon: 0.65\n",
      "Episode 39/500, Total Reward: -15, Epsilon: 0.64\n",
      "Episode 40/500, Total Reward: -15, Epsilon: 0.63\n",
      "Episode 41/500, Total Reward: -15, Epsilon: 0.63\n",
      "Episode 42/500, Total Reward: -15, Epsilon: 0.62\n",
      "Episode 43/500, Total Reward: -15, Epsilon: 0.60\n",
      "Episode 44/500, Total Reward: -15, Epsilon: 0.59\n",
      "Episode 45/500, Total Reward: -15, Epsilon: 0.58\n",
      "Episode 46/500, Total Reward: -15, Epsilon: 0.58\n",
      "Episode 47/500, Total Reward: -15, Epsilon: 0.57\n",
      "Episode 48/500, Total Reward: -15, Epsilon: 0.56\n",
      "Episode 49/500, Total Reward: -15, Epsilon: 0.56\n",
      "Episode 50/500, Total Reward: -15, Epsilon: 0.55\n",
      "Episode 51/500, Total Reward: -15, Epsilon: 0.55\n",
      "Episode 52/500, Total Reward: -15, Epsilon: 0.54\n",
      "Episode 53/500, Total Reward: -15, Epsilon: 0.52\n",
      "Episode 54/500, Total Reward: -15, Epsilon: 0.51\n",
      "Episode 55/500, Total Reward: -15, Epsilon: 0.50\n",
      "Episode 56/500, Total Reward: -15, Epsilon: 0.50\n",
      "Episode 57/500, Total Reward: -15, Epsilon: 0.49\n",
      "Episode 58/500, Total Reward: -15, Epsilon: 0.47\n",
      "Episode 59/500, Total Reward: -15, Epsilon: 0.47\n",
      "Episode 60/500, Total Reward: -15, Epsilon: 0.46\n",
      "Episode 61/500, Total Reward: -15, Epsilon: 0.45\n",
      "Episode 62/500, Total Reward: -15, Epsilon: 0.44\n",
      "Episode 63/500, Total Reward: 0, Epsilon: 0.42\n",
      "Episode 64/500, Total Reward: 50, Epsilon: 0.41\n",
      "Episode 65/500, Total Reward: -15, Epsilon: 0.40\n",
      "Episode 66/500, Total Reward: -15, Epsilon: 0.39\n",
      "Episode 67/500, Total Reward: -15, Epsilon: 0.38\n",
      "Episode 68/500, Total Reward: -15, Epsilon: 0.37\n",
      "Episode 69/500, Total Reward: -15, Epsilon: 0.37\n",
      "Episode 70/500, Total Reward: -15, Epsilon: 0.36\n",
      "Episode 71/500, Total Reward: -15, Epsilon: 0.35\n",
      "Episode 72/500, Total Reward: -15, Epsilon: 0.35\n",
      "Episode 73/500, Total Reward: -15, Epsilon: 0.34\n",
      "Episode 74/500, Total Reward: -15, Epsilon: 0.33\n",
      "Episode 75/500, Total Reward: 65, Epsilon: 0.32\n",
      "Episode 76/500, Total Reward: -15, Epsilon: 0.32\n",
      "Episode 77/500, Total Reward: -15, Epsilon: 0.31\n",
      "Episode 78/500, Total Reward: -15, Epsilon: 0.31\n",
      "Episode 79/500, Total Reward: -15, Epsilon: 0.30\n",
      "Episode 80/500, Total Reward: -15, Epsilon: 0.29\n",
      "Episode 81/500, Total Reward: -15, Epsilon: 0.29\n",
      "Episode 82/500, Total Reward: -15, Epsilon: 0.28\n",
      "Episode 83/500, Total Reward: -15, Epsilon: 0.27\n",
      "Episode 84/500, Total Reward: -15, Epsilon: 0.27\n",
      "Episode 85/500, Total Reward: -15, Epsilon: 0.27\n",
      "Episode 86/500, Total Reward: -15, Epsilon: 0.26\n",
      "Episode 87/500, Total Reward: -15, Epsilon: 0.26\n",
      "Episode 88/500, Total Reward: 0, Epsilon: 0.25\n",
      "Episode 89/500, Total Reward: 0, Epsilon: 0.24\n",
      "Episode 90/500, Total Reward: -15, Epsilon: 0.24\n",
      "Episode 91/500, Total Reward: -15, Epsilon: 0.23\n",
      "Episode 92/500, Total Reward: -15, Epsilon: 0.23\n",
      "Episode 93/500, Total Reward: -15, Epsilon: 0.22\n",
      "Episode 94/500, Total Reward: -15, Epsilon: 0.22\n",
      "Episode 95/500, Total Reward: 0, Epsilon: 0.21\n",
      "Episode 96/500, Total Reward: -15, Epsilon: 0.21\n",
      "Episode 97/500, Total Reward: -15, Epsilon: 0.20\n",
      "Episode 98/500, Total Reward: -15, Epsilon: 0.20\n",
      "Episode 99/500, Total Reward: -15, Epsilon: 0.19\n",
      "Episode 100/500, Total Reward: -15, Epsilon: 0.18\n",
      "Episode 101/500, Total Reward: -15, Epsilon: 0.18\n",
      "Episode 102/500, Total Reward: 65, Epsilon: 0.17\n",
      "Episode 103/500, Total Reward: 80, Epsilon: 0.16\n",
      "Episode 104/500, Total Reward: 95, Epsilon: 0.16\n",
      "Episode 105/500, Total Reward: 50, Epsilon: 0.15\n",
      "Episode 106/500, Total Reward: -15, Epsilon: 0.15\n",
      "Episode 107/500, Total Reward: -15, Epsilon: 0.15\n",
      "Episode 108/500, Total Reward: -15, Epsilon: 0.14\n",
      "Episode 109/500, Total Reward: -15, Epsilon: 0.14\n",
      "Episode 110/500, Total Reward: -15, Epsilon: 0.14\n",
      "Episode 111/500, Total Reward: -15, Epsilon: 0.14\n",
      "Episode 112/500, Total Reward: -15, Epsilon: 0.14\n",
      "Episode 113/500, Total Reward: -15, Epsilon: 0.13\n",
      "Episode 114/500, Total Reward: -15, Epsilon: 0.13\n",
      "Episode 115/500, Total Reward: -15, Epsilon: 0.13\n",
      "Episode 116/500, Total Reward: -15, Epsilon: 0.13\n",
      "Episode 117/500, Total Reward: -15, Epsilon: 0.13\n",
      "Episode 118/500, Total Reward: -15, Epsilon: 0.12\n",
      "Episode 119/500, Total Reward: -15, Epsilon: 0.12\n",
      "Episode 120/500, Total Reward: -15, Epsilon: 0.12\n",
      "Episode 121/500, Total Reward: -15, Epsilon: 0.12\n",
      "Episode 122/500, Total Reward: -15, Epsilon: 0.11\n",
      "Episode 123/500, Total Reward: 0, Epsilon: 0.11\n",
      "Episode 124/500, Total Reward: 0, Epsilon: 0.10\n",
      "Episode 125/500, Total Reward: -15, Epsilon: 0.10\n",
      "Episode 126/500, Total Reward: 65, Epsilon: 0.10\n",
      "Episode 127/500, Total Reward: -15, Epsilon: 0.10\n",
      "Episode 128/500, Total Reward: 65, Epsilon: 0.09\n",
      "Episode 129/500, Total Reward: -15, Epsilon: 0.09\n",
      "Episode 130/500, Total Reward: -15, Epsilon: 0.09\n",
      "Episode 131/500, Total Reward: -15, Epsilon: 0.09\n",
      "Episode 132/500, Total Reward: -15, Epsilon: 0.08\n",
      "Episode 133/500, Total Reward: -15, Epsilon: 0.08\n",
      "Episode 134/500, Total Reward: 50, Epsilon: 0.08\n",
      "Episode 135/500, Total Reward: 95, Epsilon: 0.08\n",
      "Episode 136/500, Total Reward: -15, Epsilon: 0.07\n",
      "Episode 137/500, Total Reward: -15, Epsilon: 0.07\n",
      "Episode 138/500, Total Reward: -15, Epsilon: 0.07\n",
      "Episode 139/500, Total Reward: -15, Epsilon: 0.07\n",
      "Episode 140/500, Total Reward: 80, Epsilon: 0.06\n",
      "Episode 141/500, Total Reward: -15, Epsilon: 0.06\n",
      "Episode 142/500, Total Reward: -15, Epsilon: 0.06\n",
      "Episode 143/500, Total Reward: -15, Epsilon: 0.06\n",
      "Episode 144/500, Total Reward: -15, Epsilon: 0.06\n",
      "Episode 145/500, Total Reward: -15, Epsilon: 0.06\n",
      "Episode 146/500, Total Reward: -15, Epsilon: 0.06\n",
      "Episode 147/500, Total Reward: 50, Epsilon: 0.05\n",
      "Episode 148/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 149/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 150/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 151/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 152/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 153/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 154/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 155/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 156/500, Total Reward: -15, Epsilon: 0.05\n",
      "Episode 157/500, Total Reward: -15, Epsilon: 0.04\n",
      "Episode 158/500, Total Reward: -15, Epsilon: 0.04\n",
      "Episode 159/500, Total Reward: -15, Epsilon: 0.04\n",
      "Episode 160/500, Total Reward: -15, Epsilon: 0.04\n",
      "Episode 161/500, Total Reward: -15, Epsilon: 0.04\n",
      "Episode 162/500, Total Reward: -15, Epsilon: 0.04\n",
      "Episode 163/500, Total Reward: 50, Epsilon: 0.04\n",
      "Episode 164/500, Total Reward: -15, Epsilon: 0.03\n",
      "Episode 165/500, Total Reward: 80, Epsilon: 0.03\n",
      "Episode 166/500, Total Reward: -15, Epsilon: 0.03\n",
      "Episode 167/500, Total Reward: -15, Epsilon: 0.03\n",
      "Episode 168/500, Total Reward: 50, Epsilon: 0.03\n",
      "Episode 169/500, Total Reward: 65, Epsilon: 0.03\n",
      "Episode 170/500, Total Reward: 65, Epsilon: 0.03\n",
      "Episode 171/500, Total Reward: 80, Epsilon: 0.03\n",
      "Episode 172/500, Total Reward: 80, Epsilon: 0.02\n",
      "Episode 173/500, Total Reward: 50, Epsilon: 0.02\n",
      "Episode 174/500, Total Reward: 65, Epsilon: 0.02\n",
      "Episode 175/500, Total Reward: 50, Epsilon: 0.02\n",
      "Episode 176/500, Total Reward: 50, Epsilon: 0.02\n",
      "Episode 177/500, Total Reward: 65, Epsilon: 0.02\n",
      "Episode 178/500, Total Reward: -15, Epsilon: 0.02\n",
      "Episode 179/500, Total Reward: 80, Epsilon: 0.02\n",
      "Episode 180/500, Total Reward: 50, Epsilon: 0.02\n",
      "Episode 181/500, Total Reward: 65, Epsilon: 0.02\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the environment and agent\n",
    "env = PoemGenerationEnv(df, num_verses=4, syllables_per_verse=6, rhyme_data=3)\n",
    "agent = DQLAgent(state_size, action_size)\n",
    "\n",
    "for episode in range(episodes):\n",
    "    # Reset environment at the start of each episode\n",
    "    state = env.reset()\n",
    "    state_vector = np.array([state[\"verse_index\"], state[\"syllables_left\"], len(state[\"poem\"])])\n",
    "    total_reward = 0\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Choose an action\n",
    "        action = agent.act(state_vector)\n",
    "\n",
    "        # Take the action in the environment\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state_vector = np.array([next_state[\"verse_index\"], next_state[\"syllables_left\"], len(next_state[\"poem\"])])\n",
    "\n",
    "        # Store experience\n",
    "        agent.remember(state_vector, action, reward, next_state_vector, done)\n",
    "\n",
    "        # Update state\n",
    "        state_vector = next_state_vector\n",
    "        total_reward += reward\n",
    "\n",
    "        # Replay and train\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "    # Update target network periodically\n",
    "    if episode % target_update_freq == 0:\n",
    "        agent.update_target_network()\n",
    "        # Save the Q-network weights\n",
    "        agent.q_network.save_weights(\"q_network.weights.h5\")    \n",
    "\n",
    "    print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Poem:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/poem-mode/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "env = PoemGenerationEnv(df, num_verses=4, syllables_per_verse=6, rhyme_data=3)\n",
    "agent = DQLAgent(state_size, action_size)\n",
    "agent.q_network.load_weights(\"q_network.weights.h5\")\n",
    "\n",
    "state = env.reset()\n",
    "state_vector = np.array([state[\"verse_index\"], state[\"syllables_left\"], len(state[\"poem\"])])\n",
    "\n",
    "done = False\n",
    "generated_poem = []\n",
    "\n",
    "while not done:\n",
    "    action = agent.act(state_vector)\n",
    "    next_state, reward, done = env.step(action)\n",
    "    state_vector = np.array([next_state[\"verse_index\"], next_state[\"syllables_left\"], len(next_state[\"poem\"])])\n",
    "    generated_poem = next_state[\"poem\"]\n",
    "\n",
    "print(\"Generated Poem:\")\n",
    "print(\"\\n\".join(generated_poem))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poem-mode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
